{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Calling germline variants in amplicon-based resequencing data\n",
    "\n",
    "This tutorial is based on *De novo and inherited loss-of-function\n",
    "variants in TLK2: identification, clinical delineation and\n",
    "genotype-phenotype evaluation of a distinct neurodevelopmental disorder*\n",
    "by MRF Reijnders, KA Miller et al.\n",
    "\n",
    "After identifying a possibly pathogenic mutation in TLK2, we wanted to\n",
    "screen a large cohort of patients for anybody else who carries a\n",
    "mutation in that gene. We designed primers to capture exons 2-22 and\n",
    "used a 384-sample paired-end kit to resequence 384 patients in a single\n",
    "Illumina MiSeq run.\n",
    "\n",
    "In this tutorial, we will look at how the data from this experiment was processed\n",
    "using amplimap. We will be working with a subset of three samples, to speed\n",
    "up processing times.\n",
    "\n",
    "## Analysis overview\n",
    "\n",
    "Starting from the raw sequencing reads, we would like to:\n",
    "\n",
    "-  Trim off primer sequences\n",
    "-  Align reads to the reference genome\n",
    "-  Determine whether any target regions may have not been adequately\n",
    "   covered in some of the samples\n",
    "-  Call germline variants\n",
    "-  Annotate variants with their consequences as well as allele\n",
    "   frequencies and deleteriousness scores\n",
    "-  Generate an overview table for manual inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup\n",
    "\n",
    "To run this tutorial amplimap needs to be installed and configured already.\n",
    "Please see [Installation](https://amplimap.readthedocs.io/en/latest/installation.html)\n",
    "and [Configuration](https://amplimap.readthedocs.io/en/latest/configuration.html) for details.\n",
    "\n",
    "In particular, you need to have the hg19 (GRCh37) reference FASTA genome and the\n",
    "associated indices prepared for use with your default aligner (see [Reference genome paths](https://amplimap.readthedocs.io/en/latest/configuration.html#reference-genome-paths)).\n",
    "\n",
    "In addition, you need to have [Annovar installed and your indices set up](https://amplimap.readthedocs.io/en/latest/configuration.html#setting-up-annovar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the working directory\n",
    "\n",
    "\n",
    "For every experiment that we want to process, we create a new working\n",
    "directory. This will contain all the input files required, as well as\n",
    "the output generated by amplimap. This makes it easy to keep track of\n",
    "the data for each experiment, as well as to rerun analyses if required.\n",
    "\n",
    "To create a directory, we use the standard ``mkdir`` unix command and\n",
    "change into it with ``cd``:\n",
    "\n",
    "    mkdir TLK2\n",
    "    cd TLK2\n",
    "\n",
    "All further commands should now be run inside this working directory.\n",
    "\n",
    "### reads_in\n",
    "\n",
    "\n",
    "The first input we need to provide to amplimap is of course the\n",
    "sequencing data. These can be obtained directly from the sequencer as\n",
    "``.fastq.gz`` files and should be placed in a directory called [``reads_in``](https://amplimap.readthedocs.io/en/latest/usage.html#reads-in).\n",
    "\n",
    "[Download the sample data from this tutorial](http://userweb.molbiol.ox.ac.uk/public/koelling/amplimap/tutorial_data/TLK2.tar)\n",
    "and extract the ``reads_in`` directory into your working directory. There are many different ways of doing this but\n",
    "we recommend using ``wget`` and ``tar`` on the command line:\n",
    "\n",
    "    wget http://userweb.molbiol.ox.ac.uk/public/koelling/amplimap/tutorial_data/TLK2.tar\n",
    "    tar xf TLK2.tar\n",
    "\n",
    "You can use ``ls`` to check that the files have been extracted to the correct subdirectory:\n",
    "\n",
    "    ls reads_in\n",
    "\n",
    "This should display a list of six fastq.gz files, which represent read 1\n",
    "and read 2 of three samples:\n",
    "\n",
    "    Sample1_L001_R1_001.fastq.gz  Sample1_L001_R2_001.fastq.gz\n",
    "    Sample2_L001_R1_001.fastq.gz  Sample2_L001_R2_001.fastq.gz\n",
    "    Sample3_L001_R1_001.fastq.gz  Sample3_L001_R2_001.fastq.gz\n",
    "\n",
    "\n",
    "\n",
    "### probes.csv\n",
    "\n",
    "Next, we need to provide a [probes.csv file](https://amplimap.readthedocs.io/en/latest/usage.html#probes-csv) that describes the used\n",
    "primer sequences and the regions they are supposed to capture. This can\n",
    "be created with spreadsheet software such as Excel, as long as the file is\n",
    "saved as plain text. However, we recommend always checking the file manually\n",
    "using a plain text editor such as ``nano`` or ``vim``, to make sure it is actually in the right\n",
    "format.\n",
    "\n",
    "Create a new plain text file called ``probes.csv`` (for example using ``nano``\n",
    "or ``vim``) in your working directory and copy the following text into it:\n",
    "\n",
    "    id,first_primer_5to3,second_primer_5to3,chr,target_start,target_end,strand\n",
    "    TLK2-Ex2,AATTACTGTGAGTTTTGTTCTACAG,ACTATGTTAAATGACTACTGGAATGACC,chr17,60558422,60558714,+\n",
    "    TLK2-Ex3,ACGCCATTGTATTCCAGCCGGGGTGAT,CAGCCTTGAGCCACCAAACCTGGCCCAAAC,chr17,60598019,60598245,+\n",
    "    TLK2-Ex4,TAAGAGGAAGACAGTGATTCAGGAC,GAACTAACACTGTTCTGTCAGGTG,chr17,60599449,60599800,+\n",
    "    TLK2-Ex5,TGGAGGAAATAGTCTGTTCTTG,ATGTTGCCCAGGTTGGCCTCGAACT,chr17,60600344,60600732,+\n",
    "    TLK2-Ex6,GCATAGTACTGTTTTGAATTATTCATATCG,CTCTTCTGTAAAAAGCTAATTTACTGAC,chr17,60601577,60601855,+\n",
    "    TLK2-Ex7,CTTATATTTGATAACTGTTTTTAACCCG,GAGCACTAGGGCAATGGAAAGGATA,chr17,60613463,60613723,+\n",
    "    TLK2-Ex8,GAACTTGGTATAAACCACCATGTCC,GTGGTCAGAGAAATACAGAGAAGTC,chr17,60629478,60629842,+\n",
    "    TLK2-Ex9,ATTTGTGTGAGCAAGTGCTTTTTCC,GGTGCTTGCTATAAAATCTCTTACA,chr17,60630934,60631128,+\n",
    "    TLK2-Ex10,AAACATGCCCAAATTAGTAATTCAA,CAAATCATGTTCCTAAAAAGCTCTAC,chr17,60637164,60637585,+\n",
    "    TLK2-Ex11,TTCTAAGAAGTGTCTTTATCCATGC,AGGACTTCACCTCATTCGATAC,chr17,60642320,60642640,+\n",
    "    TLK2-Ex12,AAATTGGATACACAAGTGACAAATTG,CTATTGCCGGTGACAATCAAC,chr17,60650431,60650833,+\n",
    "    TLK2-Ex13,GCTTTGAAGTTCTTCCCTCACATC,CACTGAAGCTTTCTGCTGCTATG,chr17,60653891,60654235,+\n",
    "    TLK2-Ex14,TTACTGAACTCCTCTGTATGGTTTG,AGCAATCTCCAACCCAATATGC,chr17,60655659,60655949,+\n",
    "    TLK2-Ex15,CTGGGAATTTTGCAAGCGTGG,TATGAGGCAGGAAGTACAGAACC,chr17,60657421,60657827,+\n",
    "    TLK2-Ex16,TAATCACAAGTTTCAAGAAGGTGCT,ACCAACAACAATGCACGTAAAG,chr17,60663354,60663656,+\n",
    "    TLK2-Ex17,TCTCAATGGCTTGGTAGATTCC,TGTCACAAATTACTTGGTTCCCTC,chr17,60673772,60674134,+\n",
    "    TLK2-Ex18,AGGTAGTGTTAATCTGCTTGCTC,TCCAACACGCCCTCCTAAAC,chr17,60677974,60678351,+\n",
    "    TLK2-Ex19,AGTCCAGATTGCTTGATTCCC,GCCACATCTCTATAGCCAACCTG,chr17,60679277,60679561,+\n",
    "    TLK2-Ex20,GTACATGTCTTAAACTTATATGATC,CCTAGGGTTGAGGATTTCTGCT,chr17,60683454,60683774,+\n",
    "    TLK2-Ex21,CCCACTCTGCTTTGACCTGGTAG,TTCACACTGAAGAATCCATCCA,chr17,60685195,60685580,+\n",
    "    TLK2-Ex22,AGAGGTACTTCTGTTGGTGCTT,GGATTCGCTATGTTCCAAACC,chr17,60689581,60690988,+\n",
    "\n",
    "### targets.csv\n",
    "\n",
    "We also want to describe the target regions that amplimap\n",
    "should analyse in the [targets.csv](https://amplimap.readthedocs.io/en/latest/usage.html#targets-csv) file. This helps speed up the\n",
    "process, since any reads outside the targets can be ignored. It also\n",
    "allows us to calculate the average coverage for each target in each\n",
    "sample.\n",
    "\n",
    "Create a new plain text file called ``targets.csv`` (for example using ``nano``\n",
    "or ``vim``) in your working directory and copy the following text into it:\n",
    "\n",
    "    chr,start,end,id\n",
    "    chr17,60558422,60558714,TLK2-Ex2\n",
    "    chr17,60598019,60598245,TLK2-Ex3\n",
    "    chr17,60599449,60599800,TLK2-Ex4\n",
    "    chr17,60600344,60600732,TLK2-Ex5\n",
    "    chr17,60601577,60601855,TLK2-Ex6\n",
    "    chr17,60613463,60613723,TLK2-Ex7\n",
    "    chr17,60629478,60629842,TLK2-Ex8\n",
    "    chr17,60630934,60631128,TLK2-Ex9\n",
    "    chr17,60637164,60637585,TLK2-Ex10\n",
    "    chr17,60642320,60642640,TLK2-Ex11\n",
    "    chr17,60650508,60650785,TLK2-Ex12\n",
    "    chr17,60653891,60654235,TLK2-Ex13\n",
    "    chr17,60655659,60655949,TLK2-Ex14\n",
    "    chr17,60657421,60657827,TLK2-Ex15\n",
    "    chr17,60663354,60663656,TLK2-Ex16\n",
    "    chr17,60673772,60674134,TLK2-Ex17\n",
    "    chr17,60677974,60678351,TLK2-Ex18\n",
    "    chr17,60679277,60679561,TLK2-Ex19\n",
    "    chr17,60683454,60683774,TLK2-Ex20\n",
    "    chr17,60685195,60685580,TLK2-Ex21\n",
    "    chr17,60689581,60689989,TLK2-Ex22\n",
    "\n",
    "### config.yaml\n",
    "\n",
    "Finally, we create a config.yaml file to set some experiment-specific settings.\n",
    "We could set [a lot more options](https://amplimap.readthedocs.io/en/latest/configuration.html)\n",
    "here but in this case set a few of them. All the other options will be left at\n",
    "the as specified in the default configuration.\n",
    "\n",
    "Create a new plain text file called ``config.yaml`` (for example using ``nano``\n",
    "or ``vim``) in your working directory and copy the following text into it:\n",
    "\n",
    "    general:\n",
    "      genome_name: \"hg19\"\n",
    "\n",
    "This tells amplimap to run using the reference genome hg19, as specified in your\n",
    "[default configuration](https://amplimap.readthedocs.io/en/latest/configuration.html#default-configuration).\n",
    "If you do not have this reference genome set up there, you can also specify the necessary paths directly\n",
    "in the ``config.yaml``, by adding the following additional lines and editing the paths to match your local setup:\n",
    "\n",
    "    paths:\n",
    "      hg19:\n",
    "        bwa: \"/INSERT/PATH/TO/PREFIX\"\n",
    "        fasta: \"/INSERT/PATH/TO/FASTA\"\n",
    "        annovar: \"/INSERT/PATH/TO/ANNOVAR/INDICES\"\n",
    "        \n",
    "For ``bwa`` you would provide the path of the prefix you used when [building the BWA index](http://bio-bwa.sourceforge.net/bwa.shtml#3).\n",
    "If you are using Bowtie2 as your aligner you can replace ``bwa`` with ``bowtie2`` in the config file and provide the prefix of its index files instead.\n",
    "For ``fasta`` you would provide the path to the corresponding FASTA file, which needs to have been indexed with ``samtools faidx``.\n",
    "Finally, you need to provide the path to your Annovar index directory under ``annovar``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running amplimap\n",
    "\n",
    "Now we can run amplimap. In our case, we want to obtain coverage values\n",
    "(“coverages”) and annotated variant calls (“variants”). This will also\n",
    "automatically run the other parts of the pipeline that are required,\n",
    "such as trimming the primers and aligning reads to the genome.\n",
    "First we will do a dry-run to confirm that all input files can be found:\n",
    "\n",
    "    amplimap coverages variants\n",
    "    \n",
    "This should output a long list of commands, ending with these lines:\n",
    "\n",
    "    Job counts:\n",
    "        count   jobs\n",
    "        3       align_pe\n",
    "        3       annotate_variants\n",
    "        3       calc_coverage\n",
    "        3       call_variants_raw\n",
    "        1       convert_targets_csv\n",
    "        1       copy_probes\n",
    "        1       coverage_agg\n",
    "        3       coverage_process\n",
    "        1       coverages\n",
    "        6       link_reads\n",
    "        1       merge_targets\n",
    "        3       parse_reads_pe\n",
    "        1       start_analysis\n",
    "        3       stats_alignment\n",
    "        1       stats_alignment_agg\n",
    "        1       stats_reads_agg\n",
    "        1       stats_samples_agg\n",
    "        6       tool_version\n",
    "        1       variants\n",
    "        1       variants_merge\n",
    "        1       variants_summary\n",
    "        1       variants_summary_condensed\n",
    "        46\n",
    "\n",
    "    amplimap dry run successful. Set --run to run!\n",
    "    \n",
    "You can see how amplimap is planning to run 3 alignment jobs (align_pe) and 3 variant calling jobs (call_variants),\n",
    "corresponding to the 3 samples we are analysing.\n",
    "\n",
    "Having confirmed that everything looks as expected, we can run amplimap:\n",
    "\n",
    "    amplimap coverages variants --run\n",
    "\n",
    "This will take a few minutes to complete. It would be much faster if we\n",
    "ran jobs in parallel (for example using a cluster), but we are not\n",
    "doing that for the purposes of this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the results\n",
    "\n",
    "amplimap has now processed our reads, aligned them to the reference genome, called germline variants, annotated them\n",
    "and produced a summary table with the variant calls.\n",
    "All of the output files have been placed into the ``analysis`` directory.\n",
    "\n",
    "Let's explore some of the output. Most analyses in amplimap produce one or more CSV file with a table of results. In this tutorial, we will use Python and pandas to process and visualize these files. However, the same thing could also be done in R or Excel.\n",
    "\n",
    "### analysis/reads_parsed/\n",
    "\n",
    "This directory contains results from the first step of the pipeline which\n",
    "identified primer arms in reads, trimmed them off and calculated some\n",
    "run statistics.\n",
    "\n",
    "For example, the ``stats_samples.csv`` file tells us about the number of reads in each sample and how many of these contained the expected primer sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>files</th>\n",
       "      <th>pairs_total</th>\n",
       "      <th>pairs_unknown_arms</th>\n",
       "      <th>pairs_good_arms</th>\n",
       "      <th>pairs_r1_too_short</th>\n",
       "      <th>pairs_r2_too_short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sample1</td>\n",
       "      <td>1</td>\n",
       "      <td>29218</td>\n",
       "      <td>2962</td>\n",
       "      <td>26256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sample2</td>\n",
       "      <td>1</td>\n",
       "      <td>6887</td>\n",
       "      <td>859</td>\n",
       "      <td>6028</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sample3</td>\n",
       "      <td>1</td>\n",
       "      <td>19476</td>\n",
       "      <td>1918</td>\n",
       "      <td>17558</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample  files  pairs_total  pairs_unknown_arms  pairs_good_arms  \\\n",
       "0  Sample1      1        29218                2962            26256   \n",
       "1  Sample2      1         6887                 859             6028   \n",
       "2  Sample3      1        19476                1918            17558   \n",
       "\n",
       "   pairs_r1_too_short  pairs_r2_too_short  \n",
       "0                   0                   0  \n",
       "1                   0                   0  \n",
       "2                   0                   0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.read_csv('analysis/reads_parsed/stats_samples.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for a more detailed look at the number of reads observed per probe in each sample, there is ``stats_reads.csv``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>probe</th>\n",
       "      <th>read_pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sample1</td>\n",
       "      <td>TLK2-Ex10</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sample1</td>\n",
       "      <td>TLK2-Ex11</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sample1</td>\n",
       "      <td>TLK2-Ex12</td>\n",
       "      <td>3675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sample1</td>\n",
       "      <td>TLK2-Ex13</td>\n",
       "      <td>1152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sample1</td>\n",
       "      <td>TLK2-Ex14</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample      probe  read_pairs\n",
       "0  Sample1  TLK2-Ex10         130\n",
       "1  Sample1  TLK2-Ex11         719\n",
       "2  Sample1  TLK2-Ex12        3675\n",
       "3  Sample1  TLK2-Ex13        1152\n",
       "4  Sample1  TLK2-Ex14         616"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('analysis/reads_parsed/stats_reads.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table already gives us an idea of how well we covered each of the exons in each of the samples. However, the more accurate way of looking at this is through the coverage tables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analysis/bam/coverage/\n",
    "\n",
    "This directory contains the coverage information for each sample and each target.\n",
    "The most comprehensive table to look at is ``coverages_long.csv``. In addition,\n",
    "there are also various aggregate tables that, for example, tell you the minimum coverage in each target and\n",
    "each sample (``min_coverage.csv``) or what fraction of the target was not covered by any reads (``fraction_zero_coverage.csv``).\n",
    "\n",
    "Let's load the ``fraction_zero_coverage.csv`` file and visualize the zero coverage fractions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Fraction of exon with no coverage')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_fraction = pd.read_csv('analysis/bam/coverage/fraction_zero_coverage.csv', index_col='Target')\n",
    "\n",
    "#reorder by exon number\n",
    "zero_fraction['sort_key'] = zero_fraction.index.str.replace('TLK2-Ex', '').astype(int)\n",
    "zero_fraction = zero_fraction.sort_values('sort_key').drop(columns=['sort_key'])\n",
    "\n",
    "plt.figure(figsize=(3.5, 5))\n",
    "sns.heatmap(zero_fraction, cmap='RdYlGn_r', linewidths=0.1)\n",
    "plt.title(\"Fraction of exon with no coverage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that there is one exon that had very low coverage in one of the targets. To list all targets with less than 95% coverage in at least one sample, we can use this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_fraction[zero_fraction.apply(max, axis = 1) > 0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, almost half of exon 15 (46%) was not covered at all in sample 3. We might want to try sequencing this sample again to make sure we didn't miss any mutations in this exon. Otherwise, most exons seem to have been covered quite well in all samples, as indicated by the average coverage shown in the ``cov_per_bp.csv`` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_per_bp = pd.read_csv('analysis/bam/coverage/cov_per_bp.csv', index_col='Target')\n",
    "cov_per_bp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average coverage for exon 10 was only around 10x in sample 3, but apart from that all other exons were covered to at least ~70x in all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_per_bp.apply(min, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analysis/variants_raw/\n",
    "\n",
    "Here we can find the final output of the germline variant calling -\n",
    "the annotated table of variants. The ``variants_summary.csv``\n",
    "table includes all the information one would usually find in a VCF\n",
    "file (chromosome, position, ref, alt, genotype, allele fraction, quality),\n",
    "as well as various annotations from Annovar regarding the functional\n",
    "impact and deleteriousness of the variant. There is also information\n",
    "about the frequency of the variant in reference sets, such as 1000 Genomes,\n",
    "gnomAD or ExAC.\n",
    "\n",
    "There will be one line per sample and variant, so the same variant can appear\n",
    "in multiple lines.\n",
    "\n",
    "Let's have a look at a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = pd.read_csv('analysis/variants_raw/variants_summary.csv')\n",
    "\n",
    "#fill empty cells\n",
    "variants.fillna(value={'Var_FailedFilters': '', 'ExonicFunc.refGene': '', 'ExAC_ALL': 0, 'gnomAD_genome_ALL': 0, 'CADD_phred': 0}, inplace=True)\n",
    "\n",
    "#extract columns\n",
    "variants = variants[ ['Sample', 'Target', 'Var_Zygosity', 'Var_AltFraction', 'Var_FailedFilters', 'Func.refGene', 'ExonicFunc.refGene', 'ExAC_ALL', 'gnomAD_genome_ALL', 'CADD_phred', 'Chr', 'Start', 'Ref', 'Alt'] ]\n",
    "\n",
    "\n",
    "variants.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total we found 21 variants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(variants))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of these variants seem to appear at high frequencies in the general population, as indicated by the ExAC and gnomAD frequencies. We expect pathogenic mutations in this gene to have full penetrance and know that the disease should be rare, so anything above 1% allele frequency is clearly not of interest. Thus, we filter out common variants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants[ (variants['Var_FailedFilters'] == '') & (variants['ExAC_ALL'] < 0.01) & (variants['gnomAD_genome_ALL'] < 0.01) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some intronic variant calls that do not very convincing, including one in two unrelated samples. This suggests that this is likely to be either a common polymorphism or a recurrent variant calling error. We might want to filter variants like this out by setting stricter filters, for example on the allele frequency (eg. <0.1%), the alt allele fraction (eg. > 15%) or directly on the number of samples in our screen that carried that mutation (eg. < 3).\n",
    "\n",
    "However, we also found one novel variant in sample 2 that looks very interesting: a stopgain mutation in exon 12 that has never been observed in ExAC or gnomAD, and which is predicted to be highly deleterious by CADD with a score of 39. This would certainly warrant further investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple overview table:\n",
    "variants['ID'] = variants['Sample'].str.replace('Sample', '')\n",
    "variants['gnomAD'] = variants['gnomAD_genome_ALL'] * 100.0\n",
    "variants.rename(columns={'ExonicFunc.refGene': 'Impact', 'CADD_phred': 'CADD'}).loc[\n",
    "    (variants['Var_FailedFilters'] == '') & (variants['Func.refGene'] != 'intronic'),\n",
    "    ['ID', 'Target', 'Ref', 'Alt', 'Impact', 'CADD', 'gnomAD']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional figures in high-res\n",
    "plt.figure(figsize=(3.5, 5), dpi=300)\n",
    "sns.heatmap(zero_fraction, cmap='RdYlGn_r', linewidths=0.1)\n",
    "plt.title(\"Fraction of exon with no coverage\")\n",
    "plt.ylabel(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read stats\n",
    "stats_reads = pd.read_csv('analysis/reads_parsed/stats_reads.csv')\n",
    "\n",
    "#reorder by exon number\n",
    "stats_reads['sort_key'] = stats_reads['probe'].str.replace('TLK2-Ex', '').astype(int)\n",
    "stats_reads = stats_reads.sort_values('sort_key').drop(columns=['sort_key'])\n",
    "\n",
    "plt.figure(figsize=(3.5, 6), dpi=300)\n",
    "sns.boxplot(y='probe', x='read_pairs', color='white', data=stats_reads, orient='h')\n",
    "sns.despine(bottom=True)\n",
    "plt.title(\"Read pairs per probe\")\n",
    "plt.ylabel(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!amplimap --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
